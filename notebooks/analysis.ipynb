{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Läsa in datasetet och utforska datan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Läs in datasetet\n",
    "file_path = \"../data/seattle-weather.csv\" \n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Visa de första raderna\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slutsats för ovanstående:\n",
    "\n",
    "Datasetet innehåller 6 kolumner:\n",
    "\n",
    "date: Datum för observationen.\n",
    "precipitation: Nederbörd (i mm).\n",
    "temp_max och temp_min: Högsta och lägsta temperaturer (i °C).\n",
    "wind: Vindhastighet (i m/s).\n",
    "weather: Typ av väder (t.ex. \"drizzle\", \"rain\").\n",
    "Vid första anblick verkar datasetet ha rena kolumnnamn och en rimlig struktur. Datatypen för varje kolumn bör bekräftas i nästa steg (df.info()) för att säkerställa att det kan användas i modelleringen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Läs in datasetet\n",
    "file_path = \"../data/seattle-weather.csv\" \n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Visa information om datasetet (datatyper samt minne)\n",
    "df.info()\n",
    "\n",
    "# Kontrollera om det finns några saknade värden\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasetet innehåller 1461 poster och 6 kolumner. Alla kolumner är fyllda med data (ingen saknad information , nullvärden). Kolumnerna precipitation, temp_max, temp_min, och wind är numeriska och är redan av rätt datatyp (float64), medan date och weather är av typen object. För att kunna hantera datum korrekt under analysen bör date-kolumnen konverteras till ett datetime-format. Jag kommer att utföra den konverteringen i nästa steg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Läs in datasetet\n",
    "file_path = \"../data/seattle-weather.csv\" \n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Konvertera kolumnen \"DATE\" till datetime format\n",
    "\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "\n",
    "# Visa information om datasetet (datatyper samt minne)\n",
    "df.info()\n",
    "\n",
    "# Kontrollera om det finns några saknade värden\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataförberedelse och Första Analys\n",
    "\n",
    "I detta första steget av projektet har jag börjat med att ladda in och utforska väderdatasetet från Kaggle, vilket innehåller historiska väderdata för Seattle. Datasetet har 1461 rader och 6 kolumner, som representerar: \n",
    "\n",
    "date: Datumet för vädermätningen (initialt i objektformat, men konverterat till datetime).\n",
    "precipitation: Nederbördsmängd (i mm).\n",
    "temp_max: Maximal temperatur under dagen (i °C).\n",
    "temp_min: Minsta temperatur under dagen (i °C).\n",
    "wind: Vindhastighet (i m/s).\n",
    "weather: En kategori som beskriver väderförhållandena (t.ex. regn, sol, dimma).\n",
    "\n",
    "Efter att ha läst in datasetet och visat dom först fem raderna, som bekräftar att datan ser ut att vara i rätt format , genomförde jag några grundläggande undersökningar: \n",
    "\n",
    "Datatyper: Jag kontrollerade datatyperna för varje kolumn och såg att den ursprungliga date-kolumnen var av typen object, vilket inte är optimalt för tidsanalys. För att åtgärda detta konverterade jag kolumnen till datatypen datetime64, vilket nu gör att jag kan arbeta med tidserier på ett effektivt sätt.\n",
    "\n",
    "Null-värden: Jag kontrollerade också om datasetet innehöll saknade värden (null-värden). Enligt resultaten finns det inga saknade värden i någon av kolumnerna, vilket innebär att datan är komplett och redo för vidare bearbetning.\n",
    "\n",
    "Minne och effektivitet: Med hjälp av df.info() fick jag också en översikt av minnesanvändningen och såg att datasetet är relativt litet (68.6 KB), vilket innebär att det är lätt att arbeta med i de kommande stegen.\n",
    "\n",
    "Sammanfattningsvis så har jag genomfört en inledande datainspektion och förberedelse, inklusive konvertering av datatyper och kontroll av null-värden. Datan verkar vara ren och i rätt format, vilket gör att jag nu kan fortsätta med att genomföra mer djupgående analyser och visualiseringar för att undersöka vädermönster över tid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Läs in datasetet\n",
    "file_path = \"../data/seattle-weather.csv\" \n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Konvertera kolumnen \"DATE\" till datetime format\n",
    "\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "\n",
    "# Visa information om datasetet (datatyper samt minne)\n",
    "df.info()\n",
    "\n",
    "# Kontrollera om det finns några saknade värden\n",
    "\n",
    "df.isnull().sum()\n",
    "\n",
    "# Plotta max och min temperaturen över tid\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df['date'], df['temp_max'], label='Max Temperature', color='r')\n",
    "plt.plot(df['date'], df['temp_min'], label='Min Temperature', color='b')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Temperature (°C)')\n",
    "plt.title('Temperature Variation Over Time')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sammanfattning av datahanteringen och visualisering: \n",
    "\n",
    "I denna sektion av projektet har jag läst in datasetet seattle-weather.csv och utfört några grundläggande datahanteringssteg. Först konverterades \"date\"-kolumnen till datetime-format, vilket är nödvändigt för att arbeta med tidsseriedata. Jag har också utfört en grundläggande analys av datasetet med hjälp av metoderna df.info() och df.isnull().sum(), vilket bekräftade att alla kolumner innehåller fullständiga uppsättningar av data (utan saknade värden), och att datatyperna är korrekt identifierade.\n",
    "\n",
    "För att få en överblick av temperaturvariationer över tid visualiserades maximala och minimi temperaturer med hjälp av matplotlib. Grafen visar hur temperaturerna varierar under den tidsperiod som datasetet täcker, vilket ger en första inblick i vädermönstren i Seattle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modellträning \n",
    "\n",
    "Förbereda data för modellträning.\n",
    "Jag kommer att välja funktioner och målvariabel samt dela upp data i tränings och test uppsätningar genom att använda train_test_split från sklearn.model_selection för att skapa tränings- och testuppsättningar.\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Välj funktioner och målvariabel\n",
    "# Här använder jag 'precipitation' och 'wind' för att förutspå 'temp_max'\n",
    "X = df[['precipitation', 'wind']]  # Features (här kan jag lägga till fler kolumner här)\n",
    "y = df['temp_max']  # Målvariabel (max temperatur)\n",
    "\n",
    "# Dela upp data i tränings- och testuppsättningar (80% träning, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Visa de första raderna av träningsdatan\n",
    "print(\"Träningsdata (features):\")\n",
    "print(X_train.head())\n",
    "\n",
    "print(\"Träningsdata (målvariabel):\")\n",
    "print(y_train.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bygga en modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Skapa och träna en linjär regressionsmodell\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Gör förutsägelser på testdata\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Utvärdera modellen med MSE och R2\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Skriv ut resultaten\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R-squared:\", r2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slutsats:\n",
    "Modellen är inte särskilt effektiv i sin nuvarande form, och R²-värdet tyder på att de valda funktionerna (precipitation och vind) inte förklarar mycket av variationen i max-temperaturen.\n",
    "Det kan vara värt att försöka andra funktioner eller mer avancerade modeller för att förbättra resultatet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Försöker till att förbättra modellen \n",
    "\n",
    "Steg 1: Lägg till fler funktioner\n",
    "Jag kan inkludera fler funktioner som kan ha en starkare relation till temperaturen, såsom 'temp_min' och 'weather'. Dessa kan potentiellt förbättra förutsägelserna eftersom jag nu använder mer information om vädret.\n",
    "\n",
    "Steg 2: Förbehandling av 'weather' (om det behövs)\n",
    "'weather' är en kategorisk variabel (med text som \"rain\", \"drizzle\" etc.), så jag kanske måste omvandla den till numeriska värden innan jag kan använda den i modellen. En vanlig metod verkar vara att använda One Hot Encoding, som skapar en ny kolumn för varje kategori.\n",
    "\n",
    "Steg 3: Prova en mer avancerad modell\n",
    "Jag kan byta från en enkel linjär regression till en mer kraftfull modell som Random Forest eller Gradient Boosting. Dessa modeller är bra för att hantera komplexa samband i datan.\n",
    "\n",
    "Jag börjar med att implementera detta för att se om resultatet blir bättre:\n",
    "Lägg till fler funktioner (temp_min, weather)\n",
    "Omvandla 'weather' till numeriska värden med One Hot Encoding\n",
    "Byt till en Random Forest Regressor för att göra förutsägelser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Lägg till fler funktioner: 'temp_min' och 'weather'\n",
    "X = df[['precipitation', 'wind', 'temp_min', 'weather']]  # Nu även 'temp_min' och 'weather'\n",
    "y = df['temp_max']\n",
    "\n",
    "# Omvandlar 'weather' till numeriska värden (One Hot Encoding)\n",
    "X = pd.get_dummies(X, columns=['weather'], drop_first=True)\n",
    "\n",
    "# Delar upp data i tränings- och testuppsättningar (80% träning, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Skapar och träna en Random Forest Regressor\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Gör förutsägelser\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Beräkna och visa resultat\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R-squared: {r2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analys av förbättringen \n",
    "\n",
    "Fler funktioner: Genom att inkludera in temp_min och bearbeta weather som en variabel verkar modellen kunna dra nytta av mer relevant information. Samt Random Forest modellen verkar hantera icke-linjära samband bättre än en linjär regressionsmodell kunde vilket verkar leda till en högre precision.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualisering av faktiska och predicerade värden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Prediktioner på testdatan\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Skapa en scatter plot för faktiska vs. predicerade värden\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.7, color='b')\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='r', linestyle='--', label='Perfekt linje')\n",
    "plt.xlabel('Faktiska värden (temp_max)')\n",
    "plt.ylabel('Predicerade värden (temp_max)')\n",
    "plt.title('Faktiska vs. Predicerade värden')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Histogram av residualerna (felen)\n",
    "residuals = y_test - y_pred\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(residuals, bins=30, color='purple', edgecolor='black', alpha=0.7)\n",
    "plt.xlabel('Residualer (Faktiska - Predicerade)')\n",
    "plt.ylabel('Antal')\n",
    "plt.title('Histogram av residualer')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sammanfattning: \n",
    "\n",
    "Scatterplot: Faktiska vs. Predicerade värden\n",
    "Korrelation mellan faktiska och predicerade värden:\n",
    "\n",
    "Punkterna verkar ligga nära den röda, perfekta linjen, vilket indikerar att modellen presterar bra på att förutsäga temp_max baserat på precipitation och wind.\n",
    "Dock verkar det finnas vissa avvikelser, särskilt längst ner och högst upp i skalan, vilket kan tyda på att modellen har svårigheter att hantera vissa extremer i data.\n",
    "Modellens träffsäkerhet:\n",
    "\n",
    "Generellt sett verkar modellen förutspå värden med god noggrannhet, men det finns vissa punkter långt från linjen som tyder på några större avvikelser.\n",
    "\n",
    "Histogram: Residualer\n",
    "Residualfördelning:\n",
    "\n",
    "Histogrammet visar en relativt symmetrisk och centrerad fördelning kring 0, vilket jag uppfattar är ett bra tecken.\n",
    "Detta indikerar att modellen inte är systematiskt partisk åt ett håll (t.ex. att den konsekvent över- eller underskattar).\n",
    "Spridning av residualerna:\n",
    "\n",
    "Majoriteten av residualerna ligger nära 0, vilket innebär att modellen oftast gör små fel. Det finns dock några större fel (både positiva och negativa), vilket kan tyda på att vissa datapunkter är svårare för modellen att förutsäga.\n",
    "\n",
    "Sammanfattning av slutsatser:\n",
    "Styrkor: Modellen presterar mycket bra och har en hög R² (0.84). Den kan på ett tillförlitligt sätt förutspå temp_max för majoriteten av datapunkterna.\n",
    "Svagheter: Det finns några avvikande datapunkter (outliers) och vissa extremvärden där modellen inte presterar lika bra. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
